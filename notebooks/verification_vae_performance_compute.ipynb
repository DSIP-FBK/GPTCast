{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook computes all the scores for the VAE models presented in the paper.\n",
    "We reccomend running this notebook in a GPU enabled environment. Using a reasonably fast GPU (Nvidia RTX 4090), the notebook should take around 2 hours to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing.pool import Pool\n",
    "from pysteps.verification.detcatscores import det_cat_fct_init as contingency_init\n",
    "from pysteps.verification.detcatscores import det_cat_fct_accum as contingency_accum\n",
    "from pysteps.verification.detcatscores import det_cat_fct_compute as contingency_compute\n",
    "from pysteps.verification.detcontscores import det_cont_fct_init as continuous_init\n",
    "from pysteps.verification.detcontscores import det_cont_fct_accum as continuous_accum\n",
    "from pysteps.verification.detcontscores import det_cont_fct_compute as continuous_compute\n",
    "from pysteps.utils.spectral import rapsd\n",
    "from pysteps.visualization.spectral import plot_spectrum1d\n",
    "from pysteps.verification.salscores import sal\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from gptcast.data import MiaradDataModule\n",
    "from gptcast.models import VAEGANVQ\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_reflectivity_to_rainrate(arr: np.ndarray,\n",
    "                                        minmax: tuple = (-20, 60),\n",
    "                                        a: float = 200.0,\n",
    "                                        b: float = 1.6):\n",
    "    \"\"\"\n",
    "    Input is 0 - 1 normalized reflectivity value\n",
    "        ( reflectivity (dbZ) / max reflectivity (52.5) )\n",
    "    Output is mm/h rain rate\n",
    "    \"\"\"\n",
    "    min, max = minmax\n",
    "    rescaled = arr * (max - min)\n",
    "    Z = 10.0 ** (rescaled / 10.0)  # wradlib.trafo.idecibel\n",
    "    rr = (Z / a) ** (1.0 / b)  # wradlib.zr.z_to_r\n",
    "    rr[rr < 0.04] = 0.\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MiaradDataModule.load_from_zenodo(\n",
    "    clip_and_normalize= [0,60,-1,1],\n",
    "    crop=None,\n",
    "    batch_size=8,\n",
    "    num_workers=8,\n",
    "    pin_memory=False,\n",
    ")\n",
    "md.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data/verification_vae/'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_thresholds = [.1,  .5,  1., 5., 10., 30., 50.]\n",
    "wavelength_ticks = [256, 128, 64, 32, 16, 8, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"vae_mae\", \"vae_mwae\"]\n",
    "for model in model_list:\n",
    "    ae = VAEGANVQ.load_from_zenodo(model, device=device).eval()\n",
    "    cat_tables = [contingency_init(k, axis=None) for k in test_thresholds]\n",
    "    cont_scores = continuous_init()\n",
    "    tdl = md.test_dataloader()\n",
    "    input_spectras = []\n",
    "    recons_spectras = []\n",
    "    sal_scores = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for batch in tqdm(tdl, desc=model):\n",
    "            input_image = ae.get_input(batch, 'image').to(device=device)[..., :288, :368]\n",
    "            dec, _ = ae(input_image, return_pred_indices=False)\n",
    "            \n",
    "            # rescale to 0-1\n",
    "            inpt = (input_image.cpu().numpy().squeeze().clip(-1,1)+1)/2\n",
    "            recons = (dec.cpu().numpy().squeeze().clip(-1,1)+1)/2\n",
    "\n",
    "            # compute SAL (structure, amplitude, location) score\n",
    "            # SAL scores are computed on the reflectivity\n",
    "            with Pool(8) as p:\n",
    "                sal_score = p.starmap(sal, [(recons_el*60, inpt_el*60) for inpt_el, recons_el in zip(inpt, recons)])\n",
    "            sal_scores.extend(sal_score)\n",
    "            # for inpt_el, recons_el in zip(inpt, recons):\n",
    "            #     sal_scores.append(sal(recons_el*60, inpt_el*60))\n",
    "            \n",
    "            # transform to rainrate\n",
    "            inpt = normalized_reflectivity_to_rainrate(inpt, minmax=(0,60))\n",
    "            recons = normalized_reflectivity_to_rainrate(recons, minmax=(0,60))\n",
    "\n",
    "            assert inpt.shape == recons.shape\n",
    "            assert not np.isnan(recons).any()\n",
    "            assert not np.isnan(inpt).any()\n",
    "            assert not np.isinf(recons).any()\n",
    "            assert not np.isinf(inpt).any()\n",
    "\n",
    "            # cycle through the batch and accumulate scores\n",
    "            for inpt_el, recons_el in zip(inpt, recons):\n",
    "                spectra, freq = rapsd(inpt_el, fft_method=np.fft, return_freq=True, d=1, normalize=False)\n",
    "                input_spectras.append(spectra)\n",
    "                spectra, freq = rapsd(recons_el, fft_method=np.fft, return_freq=True, d=1, normalize=False)\n",
    "                recons_spectras.append(spectra)\n",
    "            \n",
    "            for c in cat_tables:\n",
    "                contingency_accum(c, recons, inpt)\n",
    "            continuous_accum(cont_scores, recons, inpt)\n",
    "\n",
    "    cat_scores = {str(table['thr']): contingency_compute(table) for table in cat_tables}\n",
    "    cont_scores = continuous_compute(cont_scores)\n",
    "    inpt_mean_spectra = np.array(input_spectras).mean(axis=0)\n",
    "    recons_mean_spectra = np.array(recons_spectras).mean(axis=0)\n",
    "\n",
    "    #save scores to disk as CSV\n",
    "    pd.DataFrame(cat_scores).T.to_csv(os.path.join(output_dir, f'{model}.cat.csv'))\n",
    "    pd.DataFrame(cont_scores, index=[0]).to_csv(os.path.join(output_dir, f'{model}.cont.csv'))\n",
    "\n",
    "    # plot of the mean spectra of the input and reconstructed images\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    plot_spectrum1d(freq, inpt_mean_spectra, x_units='km', y_units='mm/h', color='k', lw=2, ax=ax, wavelength_ticks=wavelength_ticks, label='Input')\n",
    "    plot_spectrum1d(freq, recons_mean_spectra, x_units='km', y_units='mm/h', color='red', ax=ax, wavelength_ticks=wavelength_ticks, label='Reconstructed')\n",
    "    plt.savefig(os.path.join(output_dir, f'{model}.spectra.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # save spectra to disk as pickle\n",
    "    with open(os.path.join(output_dir, f'{model}.spectra.pkl'), 'wb') as f:\n",
    "        pickle.dump({'input': input_spectras, 'recons': recons_spectras, 'freq': freq, 'sal': sal_scores}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
